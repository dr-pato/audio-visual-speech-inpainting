<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments | Giovanni Morrone, Luca Pasa, Vadim Tikhanoff, Sonia Bergamaschi, Luciano Fadiga, Leonardo Badino University of Modena and Reggio Emilia and Istituto Italiano di Tecnologia</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Giovanni Morrone, Luca Pasa, Vadim Tikhanoff, Sonia Bergamaschi, Luciano Fadiga, Leonardo Badino University of Modena and Reggio Emilia and Istituto Italiano di Tecnologia" />
<meta property="og:description" content="Giovanni Morrone, Luca Pasa, Vadim Tikhanoff, Sonia Bergamaschi, Luciano Fadiga, Leonardo Badino University of Modena and Reggio Emilia and Istituto Italiano di Tecnologia" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments" />
<script type="application/ld+json">
{"url":"http://localhost:4000/","headline":"Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments","name":"Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments","description":"Giovanni Morrone, Luca Pasa, Vadim Tikhanoff, Sonia Bergamaschi, Luciano Fadiga, Leonardo Badino University of Modena and Reggio Emilia and Istituto Italiano di Tecnologia","@type":"WebSite","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=571b29aa368f972b0dc2fa88bd86a50b620c40dd">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments</h1>
      <h2 class="project-tagline">Giovanni Morrone, Luca Pasa, Vadim Tikhanoff, Sonia Bergamaschi, Luciano Fadiga, Leonardo Badino <br> University of Modena and Reggio Emilia and Istituto Italiano di Tecnologia</h2>
      
        <a href="http://github.com/dr-pato/audio_visual_speech_enhancement" class="btn">View on GitHub</a>
      
      
    </section>

    <section class="main-content">
      <h2 id="abstract">Abstract</h2>
<p>We address the problem of enhancing the speech of a speaker of interest in a cocktail party scenario when visual information of the speaker of interest is available. Contrary to most previous studies, we do not learn visual features on the typically small audio-visual datasets, but use an already available face landmark detector (trained on a separate image dataset). The landmarks are used by LSTM-based models to generate time-frequency masks which are applied to the acoustic mixed-speech spectrogram. Results show that: (i) landmark motion features are very effective features for this task, (ii) similarly to previous work, reconstruction of the target speakerâ€™s spectrogram mediated by masking is significantly more accurate than direct spectrogram reconstruction, and (iii) the best masks depend on both motion landmark features and the input mixed-speech spectrogram. To the best of our knowledge, our proposed models are the first models trained and evaluated on the limited size GRID and TCD-TIMIT datasets, that achieve speaker-independent speech enhancement in a multi-talker setting.</p>

<div align="center">
<iframe width="800" height="450" src="https://www.youtube.com/embed/YQ0q-OFphKM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div>

<h2 id="demos">Demos</h2>
<p>The following videos contains severals examples of enhanced speech generated by models proposed in our paper.</p>

<h3 id="grid-corpus">GRID corpus</h3>

<div align="center">
<table id="mytable" border="0">
  <tr>
    <th>2-Speakers Mix</th>
    <th>3-Speakers Mix</th> 
  </tr>
  <tr>
    <td>
		<video width="380" height="317" controls="">
		<source src="videos/grid_2spk.mp4" type="video/mp4" />
		Your browser does not support the video tag.
		</video>
	</td>
    <td>
		<video width="380" height="317" controls="">
		<source src="videos/grid_3spk.mp4" type="video/mp4" />
		Your browser does not support the video tag.
		</video>
	</td> 
  </tr>
</table>
</div>

<h3 id="tcd-timit-corpus">TCD-TIMIT corpus</h3>

<div align="center">
<table>
  <tr>
    <th>2-Speakers Mix</th>
    <th>3-Speakers Mix</th> 
  </tr>
  <tr>
    <td>
		<video width="380" height="317" controls="">
		<source src="videos/timit_2spk.mp4" type="video/mp4" />
		Your browser does not support the video tag.
		</video>
	</td>
    <td>
		<video width="380" height="317" controls="">
		<source src="videos/timit_3spk.mp4" type="video/mp4" />
		Your browser does not support the video tag.
		</video>
	</td>
  </tr>
</table>
</div>

<h2 id="paper">Paper</h2>
<p>The paper is available <a href="https://arxiv.org/abs/1811.02480">here</a>. If this project is useful for your reserch, please cite:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{morrone2018face,
  title={Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments},
  author={Morrone, Giovanni and Pasa, Luca and Tikhanoff, Vadim and Bergamaschi, Sonia and Fadiga, Luciano and Badino, Leonardo},
  journal={arXiv preprint arXiv:1811.02480},
  year={2018}
}
</code></pre></div></div>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="http://github.com/dr-pato/audio_visual_speech_enhancement">audio_visual_speech_enhancement</a> is maintained by <a href="http://github.com/dr-pato">dr-pato</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
